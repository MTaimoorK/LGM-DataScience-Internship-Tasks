{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Handwritting Recognition Using TensorFlow and Neural Networks__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: _Muhammad Taimoor Khan_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. __Importing Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. __Test Harness Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    trainX, trainY, testX, testY = load_dataset() #loading the dataset\n",
    "    trainX, testX = prep_pixels(trainX, testX) #prepare pixel data\n",
    "    scores, histories = evaluate_models(trainX, trainY) #evaluate model\n",
    "    summarize_diag(histories) #learning curves\n",
    "    summarize_perf(scores) #summarized estimated performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. __Load, Train, and Test dataset from the MNIST Dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    (trainX,trainY), (testX,testY) = mnist.load_data() #load the dataset\n",
    "    #reshape the dataset\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    #one hot code encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testX)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. __Scale The Pixels__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pixels(train, test):\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    \n",
    "    train_norm = train_norm/255.0\n",
    "    test_norm = test_norm/255.0\n",
    "    \n",
    "    return train_norm,test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. __Define the CNN Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    #now compile model\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorial_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. __Evaluate the Model Using K-Fold Cross-Validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(dataX, dataY, n_folds=5):\n",
    "    scores, histories = list(), list()\n",
    "    #preparing cross-validations\n",
    "    KFold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    #enumrate splits\n",
    "    for train_ix, test_ix in KFold.split(dataX):\n",
    "        model = define_model()\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        \n",
    "        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        _, accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "        \n",
    "        print('> %.3f ' % (accuracy * 100.0))\n",
    "        #store scores \n",
    "        scores.append(accuracy)\n",
    "        histories.append(history)\n",
    "    \n",
    "    return scores, histories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. __Plotting Learning Curves__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diag(histories):\n",
    "    for i in range(len(histories)):\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(histories[i].history['loses'], color='blue', label='train')\n",
    "        plt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "        \n",
    "        plt.subplot(2,1,2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(histories[i].history['loses'], color='blue', label='train')\n",
    "        plt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. __Summarize Model Performance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_perf(scores):\n",
    "    print('Accuracy = mean=%.3f std=%.3f n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "    \n",
    "    plt.boxplot(scores)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. __Running Test Harness__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.48 GiB for an array with shape (7840000, 256) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run_test()\n",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m, in \u001b[0;36mrun_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_test\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     trainX, trainY, testX, testY \u001b[39m=\u001b[39m load_dataset() \u001b[39m#loading the dataset\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     trainX, testX \u001b[39m=\u001b[39m prep_pixels(trainX, testX) \u001b[39m#prepare pixel data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     scores, histories \u001b[39m=\u001b[39m evaluate_models(trainX, trainY) \u001b[39m#evaluate model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m#one hot code encode target values\u001b[39;00m\n\u001b[0;32m      7\u001b[0m trainY \u001b[39m=\u001b[39m to_categorical(trainY)\n\u001b[1;32m----> 8\u001b[0m testY \u001b[39m=\u001b[39m to_categorical(testX)\n\u001b[0;32m      9\u001b[0m \u001b[39mreturn\u001b[39;00m trainX, trainY, testX, testY\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\np_utils.py:73\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     71\u001b[0m     num_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(y) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     72\u001b[0m n \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 73\u001b[0m categorical \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((n, num_classes), dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m     74\u001b[0m categorical[np\u001b[39m.\u001b[39marange(n), y] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     75\u001b[0m output_shape \u001b[39m=\u001b[39m input_shape \u001b[39m+\u001b[39m (num_classes,)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.48 GiB for an array with shape (7840000, 256) and data type float32"
     ]
    }
   ],
   "source": [
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code> The Approx Accuracy is 97% </code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
